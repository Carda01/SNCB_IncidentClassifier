{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"DoiMBKTCCf7x","executionInfo":{"status":"ok","timestamp":1732701238407,"user_tz":-60,"elapsed":520,"user":{"displayName":"Ngoc Hoang","userId":"11187860158691205978"}}},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","import os\n","import math"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"6tq-D1HICqTt"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"J2ay00gBCf7z"},"outputs":[],"source":["path = '/Users/ngochoang/Library/CloudStorage/GoogleDrive-nhungoc1508@gmail.com/My Drive/Graduate/Semester 1 (Fall 2024)/INFO-H423 Data Mining/Project/SNCB_IncidentClassifier/models/anomaly_detection'\n","os.chdir(path)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7gWHsZ17Cf70","outputId":"1e77660a-5f11-4e40-f7a2-58837abc9a08"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>incident_id</th>\n","      <th>vehicles_sequence</th>\n","      <th>events_sequence</th>\n","      <th>seconds_to_incident_sequence</th>\n","      <th>approx_lat</th>\n","      <th>approx_lon</th>\n","      <th>train_kph_sequence</th>\n","      <th>dj_ac_state_sequence</th>\n","      <th>dj_dc_state_sequence</th>\n","      <th>incident_type</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>4432881</td>\n","      <td>[609, 609, 609, 609, 609, 609, 609, 609, 609, ...</td>\n","      <td>[2744, 4004, 2852, 4110, 2854, 4396, 1132, 414...</td>\n","      <td>[-5510, -5510, -5507, -5507, -5506, -5506, -55...</td>\n","      <td>50.876601</td>\n","      <td>4.718143</td>\n","      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n","      <td>[False, False, False, False, False, False, Fal...</td>\n","      <td>[False, False, False, False, False, False, Fal...</td>\n","      <td>4</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   incident_id                                  vehicles_sequence  \\\n","0      4432881  [609, 609, 609, 609, 609, 609, 609, 609, 609, ...   \n","\n","                                     events_sequence  \\\n","0  [2744, 4004, 2852, 4110, 2854, 4396, 1132, 414...   \n","\n","                        seconds_to_incident_sequence  approx_lat  approx_lon  \\\n","0  [-5510, -5510, -5507, -5507, -5506, -5506, -55...   50.876601    4.718143   \n","\n","                                  train_kph_sequence  \\\n","0  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n","\n","                                dj_ac_state_sequence  \\\n","0  [False, False, False, False, False, False, Fal...   \n","\n","                                dj_dc_state_sequence  incident_type  \n","0  [False, False, False, False, False, False, Fal...              4  "]},"execution_count":22,"metadata":{},"output_type":"execute_result"}],"source":["df = pd.read_csv('../../data/time_sorted_table.csv', delimiter=';', index_col=0)\n","df.head(1)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"oc4zCsw1Cf71"},"outputs":[],"source":["import sys\n","import pandas as pd\n","from math import log\n","from collections import Counter\n","from ast import literal_eval\n","\n","array_cols = ['seconds_to_incident_sequence', 'vehicles_sequence', 'events_sequence',\n","                     'train_kph_sequence', 'dj_ac_state_sequence', 'dj_dc_state_sequence']\n","\n","\n","def arrify_string_columns(df: pd.DataFrame):\n","    for col in array_cols:\n","        df[col] = df[col].apply(literal_eval)\n","\n","\n","def deep_copy(df: pd.DataFrame, additional_columns = []) -> pd.DataFrame:\n","    cols_to_copy = list.copy(array_cols)\n","    copy_df = df.copy(deep=True)\n","    cols_to_copy.extend(additional_columns)\n","    cols_to_copy = set(cols_to_copy)\n","\n","    for col in cols_to_copy:\n","        if col in df:\n","            copy_df[col] = df[col].apply(list.copy)\n","\n","    return copy_df\n","\n","\n","def get_frequency(list):\n","    element_counts = Counter(list)\n","    total_elements = len(list)\n","    return {element: count / total_elements for element, count in element_counts.items()}\n","\n","\n","def calculate_tfidf(events_column, dumping_function):\n","    events = []\n","    count = Counter()\n","    for events in events_column:\n","        count.update(set(events))\n","\n","    number_of_documents_with_event = dict(count)\n","    number_of_rows = len(events_column)\n","\n","    frequencies = events_column.apply(get_frequency)\n","\n","    tfidf = {}\n","    for event in number_of_documents_with_event.keys():\n","        idf = log(number_of_rows/ number_of_documents_with_event[event])\n","        tfidf[event] = frequencies.apply(lambda x: idf * dumping_function(x.get(event, 0)))\n","\n","    return tfidf"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BZ9maqjVCf72"},"outputs":[],"source":["arrify_string_columns(df)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hA-kUEO5Cf72"},"outputs":[],"source":["embed_dict = calculate_tfidf(df['events_sequence'], lambda x: math.log(1+x))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5CwSW2mACf73","outputId":"3bc12d76-8f52-4e8c-f337-bacc9609405c"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>words</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>[PAD]</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>[UNK]</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2956</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3658</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>3636</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   words\n","0  [PAD]\n","1  [UNK]\n","2   2956\n","3   3658\n","4   3636"]},"execution_count":15,"metadata":{},"output_type":"execute_result"}],"source":["vocab_path = './embeddings/metadata.tsv'\n","vocab = pd.read_csv(vocab_path, delimiter='\\t', header=None)\n","vocab.columns = ['words']\n","vocab.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dH2dZThdCf74"},"outputs":[],"source":["embed_len = list(embed_dict.values())[0].shape[0]\n","\n","def tfidf_lookup(word):\n","    if word not in ['[PAD]', '[UNK]']:\n","        return embed_dict[int(word)].to_list()\n","    else:\n","        return [0] * embed_len"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RHEBjLNuCf74","outputId":"19846f49-ae50-4c68-9b65-4c3da0ece10b"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>words</th>\n","      <th>embed</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>[PAD]</td>\n","      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>[UNK]</td>\n","      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2956</td>\n","      <td>[0.0, 0.07554704357998568, 0.0, 0.0, 0.0, 0.05...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3658</td>\n","      <td>[0.0, 0.007127718645050187, 0.0065821222316653...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>3636</td>\n","      <td>[0.0, 0.0073795892729018485, 0.006814713238920...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   words                                              embed\n","0  [PAD]  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n","1  [UNK]  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n","2   2956  [0.0, 0.07554704357998568, 0.0, 0.0, 0.0, 0.05...\n","3   3658  [0.0, 0.007127718645050187, 0.0065821222316653...\n","4   3636  [0.0, 0.0073795892729018485, 0.006814713238920..."]},"execution_count":48,"metadata":{},"output_type":"execute_result"}],"source":["vocab['embed'] = vocab.apply(lambda x: tfidf_lookup(x.words), axis=1)\n","vocab.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nWUzGcDCCf75"},"outputs":[],"source":["with open('./embeddings/tfidf.tsv', 'w') as output_file:\n","    for i, row in vocab.iterrows():\n","        embed = [str(n) for n in row['embed']]\n","        output_file.write('\\t'.join(embed) + '\\n')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TvcqZ52oCf75"},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"base","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.13"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":0}